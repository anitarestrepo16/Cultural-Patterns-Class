{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting Taste in Movies\n",
    "\n",
    "Today, we will be testing Bourdieu’s theory of taste in contemporary movies. Specifically, in the past ten years, is good taste in movies still something that is learned and replicated in elite codes, through the institution of the movie critic? To empirically answer this question, we will address the following:\n",
    "\n",
    "1. In the past ten years, how influential are movie critic reviews in which movies are nominated for/win awards?\n",
    "    * Theoretically: Critical approval (good taste, SV), conventionally indexes prestige and distinction (O), which then is associated with the act of appreciating a film (I)\n",
    "    * Empirically: Does the probability of being nominated for an award go up with critical approval (i.e. critic scores for a movie) and down for mass approval (user scores for a movie). Historically the stamp of approval/distinction in the movie industry has been awards like the Oscars. Therefore, we will use the receipt of these awards as our outcome variable, assuming that good taste in movies can be intepreted thorugh the movies that win awards.\n",
    "\n",
    "2. Do critics still stand in opposition to movies that the masses enjoy? I.e. are critics still the gateways for elite codes?\n",
    "    * As above, critical approval indexes elite distinction from the masses\n",
    "    * Empirically: critical reviews should be either negatively or non-correlated with box-office numbers (reflecting mass enjoyment) if this theory holds\n",
    "\n",
    "3. Are “difficult” genres and words used to describe films that are nominated for awards?\n",
    "    * Theoretically: The incorporation of difficult themes and language in a movie (SV) indexes a certain ideal of high culture and sophistication (O), which is then associated with the act of appreciating a film and being sophisticated enough to understand it (I) in contrast to the \"masses\" who only enjoy “low brow” films\n",
    "    * Empirically: does the probability of being nominated for an award go up for \"serious\" genres such as drama (in comparison to comedy, for example)? How about for longer movie runtimes? For \"PG-13\" and \"R\" rated movies? For plot descriptions that closely mimic a movie critic's writing style?\n",
    "    \n",
    "To address these questions, we will rely on large text datasets from [IMDb](https://www.imdb.com/interfaces/) to identify all of the listed movies from the past 10 years, along with basic metadata about them (such as user reviews on IMDb). IMDb, however, does not give us access to awards information, critical review data, or plot description information in their available text files. For this, we will turn to the [OMDb API](http://www.omdbapi.com/) (Open Movie Database), which allows us to download all of this information, using the IMDb IDs for each movie to link movie information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import omdb\n",
    "import requests\n",
    "import json\n",
    "import nltk\n",
    "import string\n",
    "from gensim import corpora, models\n",
    "\n",
    "def logit_and_plot(formula, data, plot_title):\n",
    "    # Fit Logistic Regression Model and print summary:\n",
    "    logitfit = smf.logit(formula = formula, data = data).fit()\n",
    "    print(logitfit.summary())\n",
    "    \n",
    "    # Plot only if I'm plotting for a single variable logistic regression\n",
    "    \n",
    "    # Make Logistic Regression Predictions for each set of ratings:\n",
    "    probabilities = pd.DataFrame(logitfit.predict(), index=data.index)\n",
    "    df = pd.DataFrame()\n",
    "    if len(formula.split(\" \")) > 3:\n",
    "        return logitfit\n",
    "    elif 'averageRating' in formula.split(\" \"):\n",
    "        df = pd.DataFrame({\n",
    "            'Rating':data['averageRating'],\n",
    "            'P(Award)':probabilities[0]\n",
    "            })\n",
    "    elif 'polarization' in formula.split(\" \"):\n",
    "        df = pd.DataFrame({\n",
    "            'Rating':data['polarization'],\n",
    "            'P(Award)':probabilities[0]\n",
    "            })\n",
    "    else:\n",
    "        df = pd.DataFrame({\n",
    "            'Rating':data['metascore'],\n",
    "            'P(Award)':probabilities[0]\n",
    "            })\n",
    "    \n",
    "    # Plot mean predictions for each value if only plotting for a single variable\n",
    "    df.groupby(df.Rating).agg({'P(Award)':np.mean}).plot()\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel('Rating')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.show();\n",
    "    \n",
    "    # Return the logistic regression model itself\n",
    "    return logitfit\n",
    "\n",
    "def get_movie_data(imdb_id):\n",
    "    # Get Movie Dictionary via OMDb API, using IMDb ID #, note omdb api key needs to be filled in:\n",
    "    movie = requests.get('http://www.omdbapi.com/?i=' + imdb_id + '&plot=full&apikey=########', timeout=None)\n",
    "    movie = json.loads(movie.text, strict=False)\n",
    "\n",
    "    # Get Desired Data entries from OMDb dictionary:\n",
    "    rated = movie.get('Rated')\n",
    "    plot = movie.get('Plot')\n",
    "    metascore = movie.get('Metascore')\n",
    "    box_office = movie.get('BoxOffice')\n",
    "    awards = movie.get('Awards')\n",
    "    \n",
    "    # Return Entries as a Series to be added as new DataFrame rows\n",
    "    return pd.Series([rated, plot, metascore, box_office, awards])\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": nltk.corpus.wordnet.ADJ,\n",
    "                \"N\": nltk.corpus.wordnet.NOUN,\n",
    "                \"V\": nltk.corpus.wordnet.VERB,\n",
    "                \"R\": nltk.corpus.wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, nltk.corpus.wordnet.NOUN)\n",
    "\n",
    "def get_lemmas(text):\n",
    "\n",
    "    stop = nltk.corpus.stopwords.words('english') + list(string.punctuation)\n",
    "    tokens = [i for i in nltk.word_tokenize(text.lower()) if i not in stop]\n",
    "    lemmas = [nltk.stem.WordNetLemmatizer().lemmatize(t, get_wordnet_pos(t)) for t in tokens]\n",
    "    return lemmas\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jon Clindaniel\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\Jon Clindaniel\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# tsv is tab separated values, can read in with csv if you tell it that separator is a tab\n",
    "imdb_list = pd.read_csv('imdb_list.tsv', sep='\\t')\n",
    "imdb_info = pd.read_csv('imdb_info.tsv', sep='\\t')\n",
    "imdb_user_ratings = pd.read_csv('imdb_ratings.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logic for what terms we're going to filter out (e.g. non-movies)\n",
    "imdb_movies = imdb_list[imdb_list['titleType'] == 'movie' & # imdb_list is list of what entries are\n",
    "                       (pd.to_numeric(imdb_list['startYear'], errors = 'coerce'))<2009) & # start year is string so need to transform ino numeric\n",
    "                       (imdb_list['isAdult'] == 0)\n",
    "                       ] \n",
    "# currting data down to 100,000 entries\n",
    "imdb_movie_info = pd.merge(imdb_movies, imdb_info, how='inner', \n",
    "                          left_on='tconst', right_on='titleId') # merge other df where imdb ID number corresponds with number on other dataframe we created above (two dfs have diff column names for IDs but can specify that)\n",
    "imdb_movies_usa = imdb_movie_info[imdb_movie_info['region'] == 'US'.drop_duplicates('tconst')] # drop duplicates b/c multiple releases for US region for some movies\n",
    "imdb_movies_usa.head()\n",
    "# but don't have user ratings in this merged df - now have to add another df \n",
    "imdb_movies_usa_w_ratings = pd.merge(imdb_movies_use, imdb_user_ratings,\n",
    "                                    how = 'inner', on='tconst') # here same name for IDs\n",
    "#get rid of any movie that has too few ratings (less than ten user reviews)\n",
    "imdb_movies_final = imdb_movies_usa_w_ratings[imdb_movies_usa_w_ratings['numVotes'] >= 10]\n",
    "# now don't have critic reviews - imdb wants us to pay for pro service to access box office and critic info -> go to omdb\n",
    "# what he did (takes a long time b/c 25,000 entries so 25,000 API calls):\n",
    "def get_movie_data(imdb_id):\n",
    "    # Get Movie Dictionary via OMDb API, using IMDb ID #, note omdb api key needs to be filled in:\n",
    "    movie = requests.get('http://www.omdbapi.com/?i=' + imdb_id + '&plot=full&apikey=########', timeout=None)\n",
    "    movie = json.loads(movie.text, strict=False)\n",
    "\n",
    "    # Get Desired Data entries from OMDb dictionary:\n",
    "    rated = movie.get('Rated')\n",
    "    plot = movie.get('Plot')\n",
    "    metascore = movie.get('Metascore') #critic average\n",
    "    box_office = movie.get('BoxOffice') # gross revenue\n",
    "    awards = movie.get('Awards') \n",
    "    \n",
    "    # Return Entries as a Series to be added as new DataFrame rows\n",
    "    return pd.Series([rated, plot, metascore, box_office, awards])\n",
    "\n",
    "# load in resulting file\n",
    "imdb_movies_final = pd.read_pickle('imdb_omdb_movies_final.pkl') # pickle brings df in as is, nicer than reading in csv\n",
    "# first question: is metascore influential in terms of nominated/win awards?\n",
    "# expect correlation between metascore and awards but not with user ratings\n",
    "# first just take out columns we need\n",
    "movie_ratings = imdb_movies_final[['tconst', 'averageRating', 'metascore', 'awards']][~imdb_movies_final['metascore'].isnull()] # ~ is NOT; only return ones where there is a metascore\n",
    "# award info is in string format - need to change it\n",
    "# identify whether row has any award (NA vs. value)\n",
    "def any_award(awards):\n",
    "    if pd.isnull(awards):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "# identify whether oscar is there\n",
    "def oscar(awards): # if oscar is in awards where awards are lower case and split into a list\n",
    "    if 'oscar' in re.sub(r'[\\w\\s]', '', str(awards)).lower().split # need to deal with punctuation and other stuff w/ reg expressions (keep only words and spaces)\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "movie_ratings['Any_Award'] = movie_ratings['awards'].apply(any_award) # apply any award function over the column and create new column in df\n",
    "movie_ratings['Oscar'] = movie_ratings['awards'].apply(oscar)\n",
    "# average rating is ten point scale, metascore is on a 100 point scale so multiply average rating by ten to get on same scale\n",
    "movie_ratings['averageRating'] = movie_ratings['averageRating']*10\n",
    "# metascore is represented as string so need to turn into numbers\n",
    "movie_ratings['metascore'] = pd.to_numeric(movie_ratings['metascore'])\n",
    "# interested in polarization effect (metascore-average score) people vs. critics\n",
    "movie_ratings['polarization'] = movie_ratings['metascore'].subtract(movie_ratings['averageRating']) # more efficient than just putting in minus\n",
    "\n",
    "# ready to do some modeling!\n",
    "# scatter plot to see if any obvious relationships\n",
    "pd.plotting.scatter_matrix(movie_ratings, figsize=(20,20)); # big figure size\n",
    "\n",
    "# logistic regression - model log odds of binary phenomenon \n",
    "# odds = prob of A over prob of B\n",
    "# bigger = bigger probability of winning over not winning OScar\n",
    "# coefficients for diff. predictors will tell us whether increases or decreases odds of getting an oscar\n",
    "# complication: metascore is correlated with average user score + polarization - so need to look at interaction effects (effect to which a given variable is changed by presence of another one)\n",
    "\n",
    "# write models as strings and then plug in\n",
    "f_any_user = 'Any_Award ~ averageRating' # probs of getting any award given score of average rating - should be 0 or negative if theory is correct\n",
    "f_any_critic = 'Any-Award ~ metascore' # should be positive\n",
    "f_any_simple = 'Any_Award ~ averageRating + metascore'\n",
    "f_any_interaction = 'Any_Award ~ averageRating + metascore + averageRating*metascore'# take into account that they might not have unique contribution (overlap b/c of correlation (e/g/ when one is high the other might be particularly low, etc))\n",
    "\n",
    "# use top function to print out relationships and plot (plots not as meaningful for multiple variables)\n",
    "logit_and_plot(formula = f_any_user, data = movie_ratings, plot_title = f_any_user)\n",
    "# repeat for all the models above - more strategic to put in a loop\n",
    "\n",
    "# now repeat all for oscars\n",
    "\n",
    "# now polarization\n",
    "# add in polarization as potential interaction effect for both\n",
    "\n",
    "# movie difficulty as fancier/elite\n",
    "movie_difficulty = imdb_movies_final[['tconst', 'runtimeMinutes', 'genres', 'rated', 'plot']][\n",
    "    (~imdb_movies_final['rated'].isnull()) & (~imdb_movies_final['plot'].isnull())]# don't want entries with no rating or no plot\n",
    "# merge difficulty df with ratings df to identify whether won oscar\n",
    "ratings_difficulty = pd.merge(movie_difficulty, movie_ratings, on = 'tconst')\n",
    "ratings_difficulty['runtimeMinutes'] = pd.to_numeric(ratings_difficulty['runtimesMinutes'])\n",
    "\n",
    "# use type function to find if string or number, floats are things with decimal points, int are integers, and strings\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
