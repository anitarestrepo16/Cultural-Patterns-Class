{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contagion Models and the Prediction of Legisign Replication\n",
    "\n",
    "Today, we're going to learn how to build both simple and complex contagion simulation models using Python's [NDLib](https://ndlib.readthedocs.io/en/latest/reference/reference.html) (Network Diffusion Library) package, as well as plot the results of these simulations.\n",
    "\n",
    "Once we're comfortable with NDLib, we're going to use these models to predict the increase and decrease in legisign replication of a social media trend (the \"Tide Pod Challenge\") using the \"Kiki Challenge\" trend to fit our model. We'll be using Google Trends data as our source of data to try to get after cross-platform social media interest across the Internet.\n",
    "\n",
    "To install NDLib, run the following command on your terminal/command line:\n",
    "\n",
    "`pip install ndlib`\n",
    "\n",
    "Or, in your Jupyter notebook, you can run it like so (Warning: it can take a while to download/install):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ndlib in c:\\users\\jon clindaniel\\anaconda3\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: bokeh in c:\\users\\jon clindaniel\\anaconda3\\lib\\site-packages (from ndlib) (1.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jon clindaniel\\anaconda3\\lib\\site-packages (from ndlib) (1.16.4)\n",
      "Requirement already satisfied: future in c:\\users\\jon clindaniel\\anaconda3\\lib\\site-packages (from ndlib) (0.17.1)\n",
      "Requirement already satisfied: python-igraph in c:\\users\\jon clindaniel\\anaconda3\\lib\\site-packages (from ndlib) (0.7.1.post6)\n",
      "Requirement already satisfied: scipy in c:\\users\\jon clindaniel\\anaconda3\\lib\\site-packages (from ndlib) (1.2.1)\n",
      "Requirement already satisfied: netdispatch in c:\\users\\jon clindaniel\\anaconda3\\lib\\site-packages (from ndlib) (0.0.3)\n",
      "Requirement already satisfied: dynetx in c:\\users\\jon clindaniel\\anaconda3\\lib\\site-packages (from ndlib) (0.2.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\jon clindaniel\\anaconda3\\lib\\site-packages (from ndlib) (2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\jon clindaniel\\anaconda3\\lib\\site-packages (from bokeh->ndlib) (2.8.0)\n",
      "Requirement already satisfied: tornado>=4.3 in c:\\users\\jon clindaniel\\anaconda3\\lib\\site-packages (from bokeh->ndlib) (6.0.3)\n",
      "Requirement already satisfied: pillow>=4.0 in c:\\users\\jon clindaniel\\anaconda3\\lib\\site-packages (from bokeh->ndlib) (6.1.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in c:\\users\\jon clindaniel\\anaconda3\\lib\\site-packages (from bokeh->ndlib) (5.1.1)\n",
      "Requirement already satisfied: Jinja2>=2.7 in c:\\users\\jon clindaniel\\anaconda3\\lib\\site-packages (from bokeh->ndlib) (2.10.1)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\jon clindaniel\\anaconda3\\lib\\site-packages (from bokeh->ndlib) (1.12.0)\n",
      "Requirement already satisfied: packaging>=16.8 in c:\\users\\jon clindaniel\\anaconda3\\lib\\site-packages (from bokeh->ndlib) (19.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\jon clindaniel\\anaconda3\\lib\\site-packages (from networkx->ndlib) (4.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\jon clindaniel\\anaconda3\\lib\\site-packages (from Jinja2>=2.7->bokeh->ndlib) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\jon clindaniel\\anaconda3\\lib\\site-packages (from packaging>=16.8->bokeh->ndlib) (2.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ndlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using a Windows computer, you may need to separately download the file for the python-igraph package from [here](https://www.lfd.uci.edu/~gohlke/pythonlibs/#python-igraph) to successfully install the python-igraph package (a requirement for ndlib). The number after 'win' in the file name refers to whether you have a 32-bit or 64-bit Operating System (you can check this in your system settings in the \"About\" section. The number after 'cp' in the file name refers to your version of Python (3.7, 3.8, etc.), which you can figure out by running the command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.3\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have downloaded the correct file, put it in your local directory (or navigate to the file via the command line), and then run the command `pip install file_name`, replacing `file_name` with the name of the file that you downloaded. You should then be able to install NDLib as well via the aforementioned command `pip install ndlib`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of our packages installed, let's import what we need into this session and get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import ndlib.models.ModelConfig as mc\n",
    "import ndlib.models.epidemics as ep\n",
    "from ndlib.viz.mpl.DiffusionTrend import DiffusionTrend\n",
    "from ndlib.utils import multi_runs\n",
    "import ndlib.models.CompositeModel as gc\n",
    "from ndlib.models.compartments import NodeThreshold\n",
    "from ndlib.models.compartments import NodeStochastic\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Function simulates model given parameters and gives me y_forecasted below (mean trend)\n",
    "def simulate_net_diffusion(frac_infected = 0.01 ,threshold = 0.18, profile = 0.00001, p_removal = 0.017, num_exec = 10, num_iter=100, nproc=8):\n",
    "    # Network generation\n",
    "    g = nx.erdos_renyi_graph(1000, 0.1)\n",
    "    \n",
    "    # Composite Model instantiation\n",
    "    sir_th_model = gc.CompositeModel(g)\n",
    "\n",
    "    # Model statuses\n",
    "    sir_th_model.add_status(\"Susceptible\")\n",
    "    sir_th_model.add_status(\"Infected\")\n",
    "    sir_th_model.add_status(\"Removed\")\n",
    "\n",
    "    # Compartment definition\n",
    "    c1 = NodeThreshold(threshold=None, triggering_status=\"Infected\")\n",
    "    c2 = NodeStochastic(p_removal)\n",
    "\n",
    "    # Rule definition\n",
    "    sir_th_model.add_rule(\"Susceptible\", \"Infected\", c1)\n",
    "    sir_th_model.add_rule(\"Infected\", \"Removed\", c2)\n",
    "\n",
    "    # Model initial status configuration\n",
    "    config = mc.Configuration()\n",
    "    config.add_model_parameter('fraction_infected', frac_infected)\n",
    "\n",
    "    # Setting nodes parameters\n",
    "    for i in g.nodes():\n",
    "        config.add_node_configuration(\"threshold\", i, threshold)\n",
    "        config.add_node_configuration(\"profile\", i, profile)\n",
    "\n",
    "    # Simulation execution\n",
    "    sir_th_model.set_initial_status(config)\n",
    "    iterations = sir_th_model.iteration_bunch(num_iter)\n",
    "\n",
    "    trends = multi_runs(sir_th_model, execution_number=num_exec, iteration_number=num_iter, nprocesses=nproc)\n",
    "    \n",
    "    # convert into a dataframe that lists each number of infected nodes by iteration number (to make average calculation)\n",
    "    df_infected = pd.DataFrame([execution['trends']['node_count'][1] for execution in trends])\n",
    "    \n",
    "    # Normalize each run: based on max value being the highest - normalize around this\n",
    "    df_infected = df_infected.apply(lambda x: x/x.max(), axis=1)\n",
    "    df_infected = pd.melt(df_infected, var_name='Execution', value_name='Infected')\n",
    "    \n",
    "    # Normalize (mean) values so that they are consistent with Google Trends Data for comparison:\n",
    "    y_forecasted = df_infected.groupby('Execution').mean()* 100\n",
    "    \n",
    "    return y_forecasted\n",
    "\n",
    "# Function returns results from all simulated runs for plotting 95% Confidence Intervals of Predictions\n",
    "def full_simulate_net_diffusion(frac_infected = 0.01 ,threshold = 0.18, profile = 0.00001, p_removal = 0.017, num_exec = 10, num_iter=100, nproc=8):\n",
    "    # Network generation\n",
    "    g = nx.erdos_renyi_graph(1000, 0.1)\n",
    "    \n",
    "    # Composite Model instantiation\n",
    "    sir_th_model = gc.CompositeModel(g)\n",
    "\n",
    "    # Model statuses\n",
    "    sir_th_model.add_status(\"Susceptible\")\n",
    "    sir_th_model.add_status(\"Infected\")\n",
    "    sir_th_model.add_status(\"Removed\")\n",
    "\n",
    "    # Compartment definition\n",
    "    c1 = NodeThreshold(threshold=None, triggering_status=\"Infected\")\n",
    "    c2 = NodeStochastic(p_removal)\n",
    "\n",
    "    # Rule definition\n",
    "    sir_th_model.add_rule(\"Susceptible\", \"Infected\", c1)\n",
    "    sir_th_model.add_rule(\"Infected\", \"Removed\", c2)\n",
    "\n",
    "    # Model initial status configuration, assume 1% of population is infected\n",
    "    config = mc.Configuration()\n",
    "    config.add_model_parameter('fraction_infected', frac_infected)\n",
    "\n",
    "    # Setting nodes parameters\n",
    "    for i in g.nodes():\n",
    "        config.add_node_configuration(\"threshold\", i, threshold)\n",
    "        config.add_node_configuration(\"profile\", i, profile)\n",
    "\n",
    "    # Simulation execution\n",
    "    sir_th_model.set_initial_status(config)\n",
    "    iterations = sir_th_model.iteration_bunch(num_iter)\n",
    "\n",
    "    trends = multi_runs(sir_th_model, execution_number=num_exec, iteration_number=num_iter, nprocesses=nproc)\n",
    "    \n",
    "    # Convert into a dataframe that lists each number of infected nodes by iteration number (to make average calculation)\n",
    "    df_infected = pd.DataFrame([execution['trends']['node_count'][1] for execution in trends])\n",
    "    \n",
    "    # Normalize each run, so that they are consistent with Google Trends Data for comparison:\n",
    "    df_infected = df_infected.apply(lambda x: x/x.max(), axis=1)\n",
    "    df_infected = pd.melt(df_infected, var_name='Execution', value_name='Infected')\n",
    "    df_infected['Infected'] *= 100\n",
    "    \n",
    "    return df_infected\n",
    "\n",
    "def mse(params, y_actual, time_steps):\n",
    "    # Returns Mean Squared Error of the forecasted values, in comparison to actual values, for given parameters\n",
    "    y_forecasted = simulate_net_diffusion(threshold=params[0], profile=params[1], p_removal=params[2], num_iter=time_steps)['Infected']\n",
    "    y_forecasted.index = y_actual.index\n",
    "    \n",
    "    mse = ((y_forecasted - y_actual) ** 2).mean()\n",
    "    return np.float(mse)\n",
    "\n",
    "def optimize_net_diffusion_model(y_actual, time_steps, maxiter=1, params=[0.18, 0.00001, 0.017]): # arbitrarily chose initial parameters that were close enough in order to make this converge because need supercomputer to actually run\n",
    "    # Parameters to optimize; passing in initial parameter values as a starting \"guess\": threshold, profile, p_removal - plugging in a ton of guesses and assessing how close they are to actual data (mean square framework)\n",
    "    x0 = np.array(params)\n",
    "        \n",
    "    # Find parameters that minimize Mean Squared Error\n",
    "    result = minimize(mse, x0 , args=(y_actual, time_steps), method='nelder-mead', options={'xtol': 1e-8, 'maxiter': maxiter, 'disp': True})\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with simple contagion model\n",
    "# first need a network to create model\n",
    "# we don't have a real network data so generate random network with random connections between nodes\n",
    "g = nx.erdos_renyi_graph(1000, 0.1) # create a thousand nodes with certain probability of being connected by edges\n",
    "# SI models: with some probability, will move from susceptible to infected if come into contact with infected node\n",
    "si_model = ep.SIModel(g) # attach si model of cntagion to network from above\n",
    "config = mc.Configuration()\n",
    "config.add_model_parameter('beta', .001) # .001 probability that will become infected if come into contact with infected ndes\n",
    "# set initial number of nodes to be infected at the beginning\n",
    "config.add_model_parameter('fracton_infected', 0.05)\n",
    "si_model.set_initial_status(config) # start with those parameters\n",
    "# now let loose - set number of time steps for it to run\n",
    "iterations = si_model.iteration_bunch(100) # 100 time steps\n",
    "# combine into single trendline to describe how infectiousness is - how many people are infected over course of simulation\n",
    "trends0 = si_model.build_trends(iterations)\n",
    "# now plot w/ built in tool\n",
    "viz = DiffusionTrend(si_model, trends0)\n",
    "viz.plot()\n",
    "# simple contagion is pretty linear and then slows down and eventually everyone is infected\n",
    "\n",
    "##### complex contagion model over same random network we used\n",
    "\n",
    "## classic threshold model from 1978 - when certain number of neighboring nodes are infected, I'm also going to be infected\n",
    "th_model = ep.ThresholdModel(g) # attach threshold model to network\n",
    "# configure it\n",
    "config = mc.Configuration()\n",
    "#set threshold to .1\n",
    "threshold = .1\n",
    "# use for loop to set threshold - if want to, can set diff thresholds for diff nodes\n",
    "for n in g.nodes():\n",
    "    config.add_node_configuration(\"threshold\", n, threshold) # for each node, threshold will be threshold\n",
    "    \n",
    "config.add_model_parameter(\"fraction_infected\", 0.05)\n",
    "th_model.set_initial_status(config)\n",
    "iterations = th_model.iteration_bunch(100)\n",
    "trends1 = th_model.build_trends(iterations)\n",
    "viz = DiffusionTrend(th_model, trends1)\n",
    "viz.plot()\n",
    "# more dramatic uptake in infection - dramatically increases to 100% infection - non-linear effects\n",
    "\n",
    "### now diff. model where apply certain probability for each person after threshold is met (account for human agency)\n",
    "pth_model = ep.ProfileThresholdModel(g)\n",
    "config = mc.Configuration()\n",
    "config.add_model_parameter(\"fraction_infected\", 0.05) # 5% infected initially\n",
    "threshold = 0.15\n",
    "profile = 0.25  #probability of actually replicating legisign if infected\n",
    "# also use for loop - also have possibility to have diff. profiles for diff. nodes\n",
    "for i in g.nodes():\n",
    "    config.add_node_configuration(\"threshold\", i, threshold)\n",
    "    config.add_node_configuration(\"profile\", i, profile)\n",
    "    \n",
    "pth_model.set_intial_status(config)\n",
    "iterations = pth_model.iteration_bunch(100)\n",
    "trends2 = pth_model.build_trends(iterations)\n",
    "viz = DiffusionTrend(pth_model, trends2)\n",
    "viz.plot()\n",
    "# no infections! nodes had agency and did not choose to replicate, even when infected\n",
    "\n",
    "# when change initial infected to 10%, super quick infection\n",
    "# more curved than original threshold model because probabilistic function that decides whether peple are crossing threshold\n",
    "\n",
    "# remove parameter: to figure out when it's not poppular anymore and people are not adopting it anymore\n",
    "sir_th_model = gc.CompositeModel(g) # special class that allows you to create any compartments you want (e.g. infected, susceptible, etc)\n",
    "sir_th_model.add_status(\"Susceptible\") # one compartment\n",
    "sir_th_model.add_status(\"Infected\")\n",
    "sir_th_model.add_status(\"Removed\")\n",
    "# how to transition from one to another? need a probability. want a threshold for susceptible to infected\n",
    "c1 = NodeThreshold(threshold = None, triggering_status=\"Infected\") # if threshold goes over, will move to infected\n",
    "# create stochastic node - if infected, some probability that move over to removed\n",
    "c2 = NodeStochastic(0.05)\n",
    "# above are probabilistic conditions that define transitions. now need to add rules to define what's going on\n",
    "sir_th_model.add_rule('Susceptible', \"Infected\", c1) # when cross c1 threshold, move from susceptible to infected\n",
    "sir_th_model.add_rule(\"Infected\", \"Removed\", c2)\n",
    "# bring in material from above - from config to viz.plot\n",
    "\n",
    "\n",
    "# these are all single simulations (with multiple time steps within it) - if run multiple times, can find 95% CI and stuff\n",
    "trends = multi_runs(si_model, execution_number = 5, iteration_number = 100) # run five times (using previous simple model)\n",
    "viz = Diffusiontrend(si_model, trends)\n",
    "viz.plot(percentile = .95) # set percentile that you want - 95% CI\n",
    "# have confidence interval, have mean prediction\n",
    "\n",
    "\n",
    "\n",
    "###### predict tide pod challenge contagion\n",
    "# want to have many samples, train model using many similar contagion processes - takes a lot of time so just using kiki challenge\n",
    "# look at google trends data - these numbers are arbitrary, close enough for lack of processing power\n",
    "simulated_results_kiki = full_simulated_net_diffusion(frac_infected = 0.01, threshold = 0.038, profile = 0.0000105,\n",
    "                                                     p_removal = 0.22, num_iter = 32, num_exec = 20)\n",
    "# num_iter = 32 because look at where pattern started (first one)\n",
    "# load in data run from top\n",
    "kiki_challenge = pd.read_csv('kiki_challenge_trend.csv')\n",
    "# select where to start and stop\n",
    "kiki_challenge = kiki_challene.loc['2018-07-01': '2019-02-03']\n",
    "#rename column\n",
    "kiki_challenge.columns = ['num_infected']\n",
    "# turn numbers into strings and remove < (less than 1)\n",
    "kiki_challenge = pd.to_numeric(kik_challenge['num_infected'].str.strip(\"<\"))\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.lineplot(x = 'Execution', y = 'Infected', data = simulated_results_kiki, label = 'Simulated Results') # use seaborn because easy to make 95% CI around line plot\n",
    "# superimpose line of actual trend on top of predicted trend line using matplotlib\n",
    "plt.plot(kiki_challenge, label = \"Actual Kiki Challenge Trend\")\n",
    "plt.sticks(rotation = 90)\n",
    "plt.title .....\n",
    "\n",
    "# now check and see how it does with tide pod data\n",
    "tide_pod_challenge = pd.read_csv('tide_pod\"challenge_trend.csv')\n",
    "tide_pod_challenge = tide_pod_challenge.loc['2017-12-17': '2018-07-22'] # locate where is starts and ends\n",
    "tide_pod_challenge.columns = ['num_infected']\n",
    "tide_pod_challenge = pd.to_numeric(tide_pod_challenge['num_infected'].str.strip(\"<\"))\n",
    "plt.figure(figsize = 10,5)\n",
    "sns.lineplot(x = \"Execution\", y = \"Infected\", data = simulated_results_kiki, label = \"Prediction\")\n",
    "plt.plot(tide_pod_challene, label = \"Actual Tide Pod Challenge Trend\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
